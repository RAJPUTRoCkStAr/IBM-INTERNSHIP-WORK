{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb05500-1903-4dd1-9d00-fde439905f41",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SelectKBest, f_regression\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_boston\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_estimators\u001b[39m(estimator_type):\n\u001b[0;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m    Fetches all scikit-learn estimators of a specified type.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    - list: List of (name, class) tuples of all estimators of the specified type.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\New folder\\IBM-INTERNSHIP-WORK\\practice\\cors\\Lib\\site-packages\\sklearn\\datasets\\__init__.py:157\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_boston\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    109\u001b[0m     msg \u001b[38;5;241m=\u001b[39m textwrap\u001b[38;5;241m.\u001b[39mdedent(\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124m        `load_boston` has been removed from scikit-learn since version 1.2.\u001b[39m\n\u001b[0;32m    111\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;124m        <https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\u001b[39m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124m        \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[name]\n",
      "\u001b[1;31mImportError\u001b[0m: \n`load_boston` has been removed from scikit-learn since version 1.2.\n\nThe Boston housing prices dataset has an ethical problem: as\ninvestigated in [1], the authors of this dataset engineered a\nnon-invertible variable \"B\" assuming that racial self-segregation had a\npositive impact on house prices [2]. Furthermore the goal of the\nresearch that led to the creation of this dataset was to study the\nimpact of air quality but it did not give adequate demonstration of the\nvalidity of this assumption.\n\nThe scikit-learn maintainers therefore strongly discourage the use of\nthis dataset unless the purpose of the code is to study and educate\nabout ethical issues in data science and machine learning.\n\nIn this special case, you can fetch the dataset from the original\nsource::\n\n    import pandas as pd\n    import numpy as np\n\n    data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n    raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n    data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n    target = raw_df.values[1::2, 2]\n\nAlternative datasets include the California housing dataset and the\nAmes housing dataset. You can load the datasets as follows::\n\n    from sklearn.datasets import fetch_california_housing\n    housing = fetch_california_housing()\n\nfor the California housing dataset and::\n\n    from sklearn.datasets import fetch_openml\n    housing = fetch_openml(name=\"house_prices\", as_frame=True)\n\nfor the Ames housing dataset.\n\n[1] M Carlisle.\n\"Racist data destruction?\"\n<https://medium.com/@docintangible/racist-data-destruction-113e3eff54a8>\n\n[2] Harrison Jr, David, and Daniel L. Rubinfeld.\n\"Hedonic housing prices and the demand for clean air.\"\nJournal of environmental economics and management 5.1 (1978): 81-102.\n<https://www.researchgate.net/publication/4974606_Hedonic_housing_prices_and_the_demand_for_clean_air>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import all_estimators\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "def get_estimators(estimator_type):\n",
    "    \"\"\"\n",
    "    Fetches all scikit-learn estimators of a specified type.\n",
    "\n",
    "    Parameters:\n",
    "    - estimator_type (str): Type of estimator ('classifier' or 'regressor').\n",
    "\n",
    "    Returns:\n",
    "    - list: List of (name, class) tuples of all estimators of the specified type.\n",
    "    \"\"\"\n",
    "    if estimator_type not in ['classifier', 'regressor']:\n",
    "        raise ValueError(\"Invalid estimator type. Must be 'classifier' or 'regressor'.\")\n",
    "    \n",
    "    estimators = all_estimators(type_filter=estimator_type)\n",
    "    return list(estimators)\n",
    "\n",
    "def perform_train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    \"\"\"\n",
    "    Performs train-test split on the data.\n",
    "\n",
    "    Parameters:\n",
    "    - X (array-like): Feature dataset.\n",
    "    - y (array-like): Target values.\n",
    "    - test_size (float or int): Size of the test set.\n",
    "    - random_state (int or None): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Tuple containing train-test split of X and y: (X_train, X_test, y_train, y_test).\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "def perform_feature_selection(X, y, k=10):\n",
    "    \"\"\"\n",
    "    Performs feature selection using SelectKBest with f_regression scoring.\n",
    "\n",
    "    Parameters:\n",
    "    - X (array-like): Feature dataset.\n",
    "    - y (array-like): Target values.\n",
    "    - k (int): Number of top features to select.\n",
    "\n",
    "    Returns:\n",
    "    - array-like: Transformed feature dataset with selected features.\n",
    "    \"\"\"\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "    return X_selected\n",
    "if __name__ == \"__main__\":\n",
    "    housing = fetch_california_housing()\n",
    "    X, y = housing.data, housing.target\n",
    "    X_train, X_test, y_train, y_test = perform_train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train_selected = perform_feature_selection(X_train, y_train, k=5)\n",
    "    X_test_selected = perform_feature_selection(X_test, y_test, k=5)\n",
    "    type_of_estimator = input(\"Enter type of estimator ('classifier' or 'regressor'): \")\n",
    "    estimators = get_estimators(type_of_estimator)\n",
    "    \n",
    "    print(f\"Found {len(estimators)} {type_of_estimator}s:\")\n",
    "    for name, _ in estimators:\n",
    "        print(f\"- {name}\")\n",
    "    for name, estimator_class in estimators:\n",
    "        try:\n",
    "            estimator = estimator_class()\n",
    "            estimator.fit(X_train_selected, y_train)\n",
    "            y_pred = estimator.predict(X_test_selected)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            print(f'{name} Mean Squared Error: {mse}')\n",
    "        except Exception as e:\n",
    "            print(f'{name} failed: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0563da-1765-4cb6-980a-b8c685a4f022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import all_estimators\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import load_digits  # Example dataset, replace with user input\n",
    "\n",
    "class EstimatorManager:\n",
    "    def __init__(self):\n",
    "        self.estimators = self._get_estimators()\n",
    "        self.model = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "\n",
    "    def _get_estimators(self):\n",
    "        \"\"\"\n",
    "        Fetches all scikit-learn estimators.\n",
    "\n",
    "        Returns:\n",
    "        - list: List of (name, class) tuples of all estimators.\n",
    "        \"\"\"\n",
    "        all_estimators_dict = all_estimators()\n",
    "        estimators = [(name, EstimatorClass) for name, EstimatorClass in all_estimators_dict]\n",
    "        return estimators\n",
    "\n",
    "    def select_model(self, model_name):\n",
    "        \"\"\"\n",
    "        Selects a scikit-learn model by name.\n",
    "\n",
    "        Parameters:\n",
    "        - model_name (str): Name of the scikit-learn estimator.\n",
    "\n",
    "        Raises:\n",
    "        - ValueError: If the specified model name is not found.\n",
    "\n",
    "        Returns:\n",
    "        - bool: True if model selection is successful.\n",
    "        \"\"\"\n",
    "        for name, estimator_class in self.estimators:\n",
    "            if model_name.lower() == name.lower():\n",
    "                self.model = estimator_class()\n",
    "                return True\n",
    "        raise ValueError(f\"Model '{model_name}' not found in scikit-learn.\")\n",
    "\n",
    "    def provide_dataset(self, X, y):\n",
    "        \"\"\"\n",
    "        Accepts a dataset for model training.\n",
    "\n",
    "        Parameters:\n",
    "        - X (array-like): Feature dataset.\n",
    "        - y (array-like): Target values.\n",
    "\n",
    "        Returns:\n",
    "        - bool: True if dataset is successfully provided.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        return True\n",
    "\n",
    "    def make_graphs(self, num_graphs):\n",
    "        \"\"\"\n",
    "        Generates example graphs using the dataset.\n",
    "\n",
    "        Parameters:\n",
    "        - num_graphs (int): Number of graphs to generate.\n",
    "\n",
    "        Returns:\n",
    "        - list: List of generated graphs (matplotlib figures).\n",
    "        \"\"\"\n",
    "        if self.X is None or self.y is None:\n",
    "            raise ValueError(\"Dataset not provided.\")\n",
    "        \n",
    "        graphs = []\n",
    "        for _ in range(num_graphs):\n",
    "            # Example graph generation (replace with actual graphing logic)\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.scatter(self.X[:, 0], self.y)\n",
    "            ax.set_title(\"Example Scatter Plot\")\n",
    "            graphs.append(fig)\n",
    "        \n",
    "        return graphs\n",
    "\n",
    "    def train_and_predict(self):\n",
    "        \"\"\"\n",
    "        Trains the selected model on the provided dataset and makes predictions.\n",
    "\n",
    "        Returns:\n",
    "        - array-like: Predicted values.\n",
    "        \"\"\"\n",
    "        if self.model is None or self.X is None or self.y is None:\n",
    "            raise ValueError(\"Model or dataset not provided.\")\n",
    "\n",
    "        # Example: Train-test split for demonstration\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Train the model\n",
    "        self.model.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        # Example evaluation (replace with user's specific needs)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage script\n",
    "\n",
    "    # Initialize EstimatorManager\n",
    "    estimator_manager = EstimatorManager()\n",
    "\n",
    "    # Example: Select model\n",
    "    model_name = input(\"Enter model name (e.g., 'LinearRegression', 'RandomForestRegressor'): \")\n",
    "    estimator_manager.select_model(model_name)\n",
    "\n",
    "    # Example: Provide dataset (replace with user input logic)\n",
    "    digits = load_digits()\n",
    "    X, y = digits.data, digits.target\n",
    "    estimator_manager.provide_dataset(X, y)\n",
    "\n",
    "    # Example: Generate graphs (replace with user input logic)\n",
    "    num_graphs = int(input(\"Enter number of graphs to generate: \"))\n",
    "    graphs = estimator_manager.make_graphs(num_graphs)\n",
    "    for i, graph in enumerate(graphs):\n",
    "        graph.savefig(f'graph_{i}.png')  # Save or display the graphs\n",
    "\n",
    "    # Example: Train and predict\n",
    "    try:\n",
    "        predictions = estimator_manager.train_and_predict()\n",
    "        print(\"Predictions:\", predictions)\n",
    "    except ValueError as e:\n",
    "        print(e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
