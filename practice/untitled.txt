Selection deleted
for name, class_ in estimators:
    try:
        model = class_()
        # Check if the model requires specific conditions
        if hasattr(model, 'n_features_in_'):
            if x_train.shape[1] != model.n_features_in_:
                print(f'{name} requires {model.n_features_in_} features, but the data has {x_train.shape[1]} features.')
                continue

        # Check if the model can be fitted
        print(f'Training {name}')
        model.fit(x_train, y_train)
        y_pred = model.predict(x_test)
        mse = mean_squared_error(y_test, y_pred)*100
        print(f'{name} Mean Squared Error: {math.floor(mse)}')
        
        # Add to the list of successful regression models
        regression_estimators.append((name, mse))
        
    except Exception as e:
        print(f'{name} failed: {e}')
print("\nSuccessful regression models and their MSE:")
for name, mse in regression_estimators:
    print(f'{name}: {mse}')
Training ARDRegression
ARDRegression Mean Squared Error: 20
Training AdaBoostRegressor
AdaBoostRegressor Mean Squared Error: 18
Training BaggingRegressor
BaggingRegressor Mean Squared Error: 18
Training BayesianRidge
BayesianRidge Mean Squared Error: 18
Training CCA
CCA failed: `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.
Training DecisionTreeRegressor
DecisionTreeRegressor Mean Squared Error: 29
Training DummyRegressor
DummyRegressor Mean Squared Error: 22
Training ElasticNet
ElasticNet Mean Squared Error: 19
Training ElasticNetCV
ElasticNetCV Mean Squared Error: 18
Training ExtraTreeRegressor
ExtraTreeRegressor Mean Squared Error: 31
Training ExtraTreesRegressor
ExtraTreesRegressor Mean Squared Error: 18
Training GammaRegressor
GammaRegressor failed: Some value(s) of y are out of the valid range of the loss 'HalfGammaLoss'.
Training GaussianProcessRegressor
GaussianProcessRegressor Mean Squared Error: 33
Training GradientBoostingRegressor
GradientBoostingRegressor Mean Squared Error: 17
Training HistGradientBoostingRegressor
HistGradientBoostingRegressor Mean Squared Error: 21
Training HuberRegressor
HuberRegressor Mean Squared Error: 19
Training IsotonicRegression
IsotonicRegression failed: Isotonic regression input X should be a 1d array or 2d array with 1 feature
Training KNeighborsRegressor
KNeighborsRegressor Mean Squared Error: 18
Training KernelRidge
KernelRidge Mean Squared Error: 18
Training Lars
Lars Mean Squared Error: 18
Training LarsCV
LarsCV Mean Squared Error: 18
Training Lasso
Lasso Mean Squared Error: 19
Training LassoCV
LassoCV Mean Squared Error: 18
Training LassoLars
LassoLars Mean Squared Error: 19
Training LassoLarsCV
LassoLarsCV Mean Squared Error: 18
Training LassoLarsIC
LassoLarsIC Mean Squared Error: 18
Training LinearRegression
LinearRegression Mean Squared Error: 18
Training LinearSVR
LinearSVR Mean Squared Error: 62
Training MLPRegressor
C:\Users\Sumit\Desktop\New folder\IBM-INTERNSHIP-WORK\practice\cors\Lib\site-packages\sklearn\svm\_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.
  warnings.warn(
C:\Users\Sumit\Desktop\New folder\IBM-INTERNSHIP-WORK\practice\cors\Lib\site-packages\sklearn\svm\_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  warnings.warn(
MLPRegressor Mean Squared Error: 19
MultiOutputRegressor failed: MultiOutputRegressor.__init__() missing 1 required positional argument: 'estimator'
Training MultiTaskElasticNet
MultiTaskElasticNet failed: For mono-task outputs, use ElasticNet
Training MultiTaskElasticNetCV
MultiTaskElasticNetCV failed: For mono-task outputs, use ElasticNetCVCV
Training MultiTaskLasso
MultiTaskLasso failed: For mono-task outputs, use ElasticNet
Training MultiTaskLassoCV
MultiTaskLassoCV failed: For mono-task outputs, use LassoCVCV
Training NuSVR
NuSVR Mean Squared Error: 22
Training OrthogonalMatchingPursuit
OrthogonalMatchingPursuit Mean Squared Error: 19
Training OrthogonalMatchingPursuitCV
OrthogonalMatchingPursuitCV Mean Squared Error: 18
Training PLSCanonical
PLSCanonical failed: `n_components` upper bound is 1. Got 2 instead. Reduce `n_components`.
Training PLSRegression
PLSRegression Mean Squared Error: 18
Training PassiveAggressiveRegressor
PassiveAggressiveRegressor Mean Squared Error: 25
Training PoissonRegressor
PoissonRegressor Mean Squared Error: 19
Training QuantileRegressor
QuantileRegressor Mean Squared Error: 21
Training RANSACRegressor
RANSACRegressor Mean Squared Error: 33
Training RadiusNeighborsRegressor
RadiusNeighborsRegressor Mean Squared Error: 33
Training RandomForestRegressor
C:\Users\Sumit\Desktop\New folder\IBM-INTERNSHIP-WORK\practice\cors\Lib\site-packages\numpy\core\numeric.py:407: RuntimeWarning: invalid value encountered in cast
  multiarray.copyto(res, fill_value, casting='unsafe')
RandomForestRegressor Mean Squared Error: 17
RegressorChain failed: _BaseChain.__init__() missing 1 required positional argument: 'base_estimator'
Training Ridge
Ridge Mean Squared Error: 18
Training RidgeCV
RidgeCV Mean Squared Error: 18
Training SGDRegressor
SGDRegressor Mean Squared Error: 1175034705521534419112820736
Training SVR
SVR Mean Squared Error: 20
StackingRegressor failed: StackingRegressor.__init__() missing 1 required positional argument: 'estimators'
Training TheilSenRegressor
TheilSenRegressor Mean Squared Error: 18
Training TransformedTargetRegressor
TransformedTargetRegressor Mean Squared Error: 18
Training TweedieRegressor
TweedieRegressor Mean Squared Error: 18
VotingRegressor failed: VotingRegressor.__init__() missing 1 required positional argument: 'estimators'

Successful regression models and their MSE:
ARDRegression: 0.20261452422565385
AdaBoostRegressor: 0.18472556567820808
BaggingRegressor: 0.19052083333333333
BayesianRidge: 0.18412470154081473
DecisionTreeRegressor: 0.28125
DummyRegressor: 0.22265624999999992
ElasticNet: 0.19372622275860296
ElasticNetCV: 0.1898332745798886
ExtraTreeRegressor: 0.3541666666666667
ExtraTreesRegressor: 0.19047291666666666
GaussianProcessRegressor: 0.33330185711601196
GradientBoostingRegressor: 0.17928895854958826
HistGradientBoostingRegressor: 0.21442972153309056
HuberRegressor: 0.19054588459423397
KNeighborsRegressor: 0.18895833333333337
KernelRidge: 0.18411023267141946
Lars: 0.18046811126519977
LarsCV: 0.18987819093081093
Lasso: 0.193671344523364
LassoCV: 0.18983202869980195
LassoLars: 0.193671344523364
LassoLarsCV: 0.18987819093081093
LassoLarsIC: 0.18046811126519977
LinearRegression: 0.1804681112651997
LinearSVR: 0.30874246665682353
MLPRegressor: 0.18293338633815473
NuSVR: 0.2262755674026531
OrthogonalMatchingPursuit: 0.19591563512604174
OrthogonalMatchingPursuitCV: 0.1804681112651997
PLSRegression: 0.18200935506810903
PassiveAggressiveRegressor: 0.27196046529666323
PoissonRegressor: 0.19014601422281432
QuantileRegressor: 0.2111646345081286
RANSACRegressor: 0.3333333333333333
RadiusNeighborsRegressor: 0.3333333333333333
RandomForestRegressor: 0.18471770833333334
Ridge: 0.18046919106474538
RidgeCV: 0.18047889524462993
SGDRegressor: 1.6107670580519068e+25
SVR: 0.20333388938845628
TheilSenRegressor: 0.1844095788209312
TransformedTargetRegressor: 0.1804681112651997
TweedieRegressor: 0.18104198568559438
ARDRegression: 20.261452422565384
AdaBoostRegressor: 18.581326467630195
BaggingRegressor: 18.781250000000004
BayesianRidge: 18.412470154081472
DecisionTreeRegressor: 29.6875
DummyRegressor: 22.265624999999993
ElasticNet: 19.372622275860294
ElasticNetCV: 18.98332745798886
ExtraTreeRegressor: 31.770833333333332
ExtraTreesRegressor: 18.579166666666666
GaussianProcessRegressor: 33.330185711601196
GradientBoostingRegressor: 17.966979195639766
HistGradientBoostingRegressor: 21.442972153309057
HuberRegressor: 19.054588459423396
KNeighborsRegressor: 18.895833333333336
KernelRidge: 18.411023267141946
Lars: 18.046811126519977
LarsCV: 18.987819093081093
Lasso: 19.367134452336398
LassoCV: 18.983202869980197
LassoLars: 19.367134452336398
LassoLarsCV: 18.987819093081093
LassoLarsIC: 18.046811126519977
LinearRegression: 18.04681112651997
LinearSVR: 62.74388779288087
MLPRegressor: 19.49040408723236
NuSVR: 22.62755674026531
OrthogonalMatchingPursuit: 19.591563512604175
OrthogonalMatchingPursuitCV: 18.04681112651997
PLSRegression: 18.200935506810904
PassiveAggressiveRegressor: 25.914199827439933
PoissonRegressor: 19.014601422281434
QuantileRegressor: 21.116463450812862
RANSACRegressor: 33.33333333333333
RadiusNeighborsRegressor: 33.33333333333333
RandomForestRegressor: 17.71114583333333
Ridge: 18.046919106474537
RidgeCV: 18.04788952446299
SGDRegressor: 1.1750347055215344e+27
SVR: 20.33338893884563
TheilSenRegressor: 18.12392142056186
TransformedTargetRegressor: 18.04681112651997
TweedieRegressor: 18.104198568559436